{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import library\n",
        "This section for list of libraries that will use"
      ],
      "metadata": {
        "id": "GbI-vGt05nWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LDVZ7YcuRrS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uses the commands `from` google.colab `import` drive and drive.mount `('/content/drive')` to link Google Drive with Google Colab, which allows you to access files and datasets stored on Google Drive and save code execution results to them."
      ],
      "metadata": {
        "id": "JkzgIRzxY51s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RPN25QEHHY9",
        "outputId": "008b22e9-c2ca-4b2b-9bd0-07db4471ac5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then uses the zip file library to extract the contents of the zip file into the specified directory."
      ],
      "metadata": {
        "id": "yq7CW03DZv6a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-tcHzK3aowl"
      },
      "outputs": [],
      "source": [
        "local_zip = '/content/drive/MyDrive/Colab_Notebooks/waste-dataset.zip'\n",
        "extractdir = \"./\"\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall(extractdir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data\n",
        "\n",
        "We define a function called split_data which is used to split the dataset into training data and testing data based on the proportion specified by `SPLIT_SIZE`.\n",
        "\n",
        "\n",
        "\n",
        "First, we use the function random.sample to randomize the order of the files in the source directory `(SOURCE)`. The results are stored in the `shuffled_source` variable, which is a shuffled list of files.\n",
        "\n",
        "\n",
        "\n",
        "Next, we calculate the total number of files to use for the training data based on SPLIT_SIZE. The `training_number` variable stores this value.\n",
        "\n",
        "\n",
        "\n",
        "Next, we use a for loop to iterate through each item in shuffled_source. Each item is represented by the full path item_source by concatenating SOURCE and item.\n",
        "\n",
        "\n",
        "\n",
        "In the loop, we check if the file size `(os.path.getsize(item_source))` is equal to 0. If it is, then the file is assumed to be of zero length and is ignored. If not, then the file is copied `(using copyfile)` to the appropriate target directory `(target)` with the same name.\n",
        "\n",
        "\n",
        "\n",
        "When the number of copied files `(i)` reaches training_number, we change the target to the TESTING directory. This means that subsequent files copied will go into the TESTING directory, thus dividing the dataset into training and test data according to the specified proportions.\n",
        "\n",
        "\n",
        "\n",
        "Using the `split_data` function, you can split the dataset into training and test data by a certain proportion, based on a given source directory.\n",
        "\n"
      ],
      "metadata": {
        "id": "Yp3UolsJaQsn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdFoxB59cS1D"
      },
      "outputs": [],
      "source": [
        "# Function split_data\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    # Shuffle list\n",
        "    shuffled_source = random.sample(os.listdir(SOURCE), len(os.listdir(SOURCE)))\n",
        "    # Find total number of files in training dir\n",
        "    training_number = int(len(shuffled_source) * SPLIT_SIZE)\n",
        "    i = 0\n",
        "    target = TRAINING\n",
        "\n",
        "    for item in shuffled_source:\n",
        "        item_source = os.path.join(SOURCE, item)\n",
        "        if os.path.getsize(item_source) == 0:\n",
        "            print(f'{item} is zero length, so ignoring.')\n",
        "        else:\n",
        "            copyfile(item_source, os.path.join(target, item))\n",
        "            i += 1\n",
        "\n",
        "    # Switch copy target to TESTING\n",
        "        if i == training_number:\n",
        "            target = TESTING"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use source_path variable to store source directory path. Then, using `os.path.join`, we join the path with the `\"O\"` and `\"R\"` directories, which are stored in the `source_path_O` and `source_path_R` variables.\n",
        "\n",
        "Next, using `os.listdir`, we get a list of files inside the `source_path_O` and `source_path_R` directories. By using the len function, we count the number of files in each of these directories, then print the results using the f-string.\n",
        "\n",
        "By running this code, we can see how many files are in the `\"O\"` and `\"R\"` directories in the `'waste-dataset/imgWaste'` dataset."
      ],
      "metadata": {
        "id": "nFi1z4EMcCJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOvsN8uUc_fc",
        "outputId": "4a7d80ad-fea2-447f-adc2-bc2ab0ebbfff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 13966 images of O.\n",
            "There are 11111 images of R.\n"
          ]
        }
      ],
      "source": [
        "source_path = './waste-dataset/imgWaste'\n",
        "\n",
        "source_path_O = os.path.join(source_path, 'O')\n",
        "source_path_R = os.path.join(source_path, 'R')\n",
        "\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_O))} images of O.\")\n",
        "print(f\"There are {len(os.listdir(source_path_R))} images of R.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code, we define the variable root_dir to store the main directory path. If the directory already exists, we remove it using shutil.rmtree.\n",
        "\n",
        "Next, we define a function called create_train_test_dirs that creates the necessary directory structure for the training and testing dataset. We use `os.makedirs` and `os.path.join` to create the \"training\" and \"testing\" directories within `root_dir`, each containing the subdirectories `\"O\"` and `\"R\"`.\n",
        "\n",
        "Then, we attempt to execute the `create_train_test_dirs` function by passing `root_dir` as an argument. If a FileExistsError occurs, we print a message that should not be visible since the main directory has been deleted beforehand.\n",
        "\n",
        "By running this code, we can create the appropriate directory structure for the training and testing dataset."
      ],
      "metadata": {
        "id": "MO__ZRuxE8PC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rADNnQCqh5Ax"
      },
      "outputs": [],
      "source": [
        "# Define root directory\n",
        "root_dir = './waste-dataset/data'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# GRADED FUNCTION: create_train_test_dirs\n",
        "def create_train_test_dirs(root_path):\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # HINT:\n",
        "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
        "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
        "  os.makedirs(os.path.join(root_path, 'training'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/training', 'O'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/training', 'R'))\n",
        "  os.makedirs(os.path.join(root_path, 'testing'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/testing', 'O'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/testing', 'R'))\n",
        "  ### END CODE HERE\n",
        "\n",
        "\n",
        "try:\n",
        "  create_train_test_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code, we are testing the `create_train_test_dirs` function by iterating through the directories and subdirectories within the `root_dir`.\n",
        "\n",
        "We use `os.walk` to traverse the directory tree starting from `root_dir`. For each directory encountered, we print the full path by combining rootdir and subdir using `os.path.join`. This allows us to verify the directory structure created by the `create_train_test_dirs` function.\n",
        "\n",
        "By running this code, we can examine the directories and subdirectories within `root_dir` and ensure that the necessary directory structure for the training and testing dataset has been created."
      ],
      "metadata": {
        "id": "P7B-81PaeHOv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OiqhRkDh_vC",
        "outputId": "772856c1-7bde-4d78-e26c-7c6809b989f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./waste-dataset/data\\testing\n",
            "./waste-dataset/data\\training\n",
            "./waste-dataset/data\\testing\\O\n",
            "./waste-dataset/data\\testing\\R\n",
            "./waste-dataset/data\\training\\O\n",
            "./waste-dataset/data\\training\\R\n"
          ]
        }
      ],
      "source": [
        "# Test your create_train_test_dirs function\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code, we have a function called `split_data` which is used to split data into training and testing sets based on the specified `SPLIT_SIZE`.\n",
        "\n",
        "Inside the function, we first shuffle the list of files in the SOURCE directory using random.sample. This ensures that the files are randomly ordered.\n",
        "\n",
        "Next, we calculate the number of files that should be included in the training set based on the `SPLIT_SIZE`. The training_number is determined by multiplying the total number of files in SOURCE by `SPLIT_SIZE` and converting it to an integer.\n",
        "\n",
        "We then iterate through each item `(file)` in the shuffled list. For each item, we check if its size is zero. If it is, we ignore it and print a message indicating that it has zero length. Otherwise, we copy the file from SOURCE to the target directory (which starts as the TRAINING directory) using copyfile from the shutil module. We also increment the counter i.\n",
        "\n",
        "When the number of copied files (i) reaches the `training_number`, we switch the target directory to the TESTING directory. This ensures that the remaining files are copied to the testing directory.\n",
        "\n",
        "By executing this code, the data from the SOURCE directory will be split into the training and testing directories based on the specified split size."
      ],
      "metadata": {
        "id": "Ep43ql5GepOv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suKdqVNziJlY"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: split_data\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "\n",
        "  ### START CODE HERE\n",
        "  # Shuffle list\n",
        "  shuffled_source = random.sample(os.listdir(SOURCE), len(os.listdir(SOURCE)))\n",
        "\n",
        "  # Find total number of files in training dir\n",
        "  training_number = int(len(shuffled_source) * SPLIT_SIZE)\n",
        "\n",
        "  i = 0\n",
        "  target = TRAINING\n",
        "\n",
        "  for item in shuffled_source:\n",
        "    item_source = os.path.join(SOURCE, item)\n",
        "    if os.path.getsize(item_source) == 0:\n",
        "      print(f'{item} is zero length, so ignoring.')\n",
        "    else:\n",
        "      copyfile(item_source, os.path.join(target, item))\n",
        "      i += 1\n",
        "\n",
        "    # Switch copy target to TESTING\n",
        "    if i == training_number:\n",
        "      target = TESTING\n",
        "  ### END CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code, we are testing the split_data function by splitting the data from the `\"O\"` and `\"R\"` source directories into training and testing directories.\n",
        "\n",
        "First, we define the source directories (`O_SOURCE_DIR` and `R_SOURCE_DIR`) and the destination directories for training and testing (`TRAINING_DIR` and `TESTING_DIR`).\n",
        "\n",
        "To ensure that the directories are empty in case the code is run multiple times, we check if they contain any files using `len(os.listdir)` and remove the files if present using `os.remove`.\n",
        "\n",
        "Next, we define the split size (`split_size`), which determines the proportion of images used for training.\n",
        "\n",
        "Then, we execute the `split_data` function twice, once for the `\"O\"` source directory and once for the `\"R\"` source directory. This splits the data into the corresponding training and testing directories based on the specified split size.\n",
        "\n",
        "Finally, we check the number of images in the training and testing directories using `len(os.listdir)` and print the results.\n",
        "\n",
        "By running this code, we can split the data from the `\"O\"` and `\"R\"` source directories into training and testing directories, and verify the number of images in each directory."
      ],
      "metadata": {
        "id": "Hh5a7ffgfNT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6GaQR00iKuo",
        "outputId": "d1cf9da7-c080-44b8-9b73-97b7b5a32c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "There are 12569 images of O for training\n",
            "There are 9999 images of R for training\n",
            "There are 1397 images of O for testing\n",
            "There are 1112 images of R for testing\n"
          ]
        }
      ],
      "source": [
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "O_SOURCE_DIR = \"./waste-dataset/imgWaste/O\"\n",
        "R_SOURCE_DIR = \"./waste-dataset/imgWaste/R\"\n",
        "\n",
        "TRAINING_DIR = \"./waste-dataset/data/training/\"\n",
        "TESTING_DIR = \"./waste-dataset/data/testing/\"\n",
        "\n",
        "TRAINING_O_DIR = os.path.join(TRAINING_DIR, \"O/\")\n",
        "TESTING_O_DIR = os.path.join(TESTING_DIR, \"O/\")\n",
        "\n",
        "TRAINING_R_DIR = os.path.join(TRAINING_DIR, \"R/\")\n",
        "TESTING_R_DIR = os.path.join(TESTING_DIR, \"R/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_O_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_O_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_R_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_R_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_O_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_O_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_R_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_R_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .9\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(O_SOURCE_DIR, TRAINING_O_DIR, TESTING_O_DIR, split_size)\n",
        "split_data(R_SOURCE_DIR, TRAINING_R_DIR, TESTING_R_DIR, split_size)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_O_DIR))} images of O for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_R_DIR))} images of R for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_O_DIR))} images of O for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_R_DIR))} images of R for testing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentation\n",
        "In the provided code, we have a function called `train_val`_generators that creates and returns generator objects for training and validation data.\n",
        "\n",
        "Inside the function, we instantiate two ImageDataGenerator objects, one for training data (`train_datagen`) and one for validation data (`validation_datagen`). The rescale argument is set to `1./255`. to normalize the pixel values of the images.\n",
        "\n",
        "We then use the `flow_from_directory` method of each ImageDataGenerator object to create generator objects. For the training generator, we pass the `TRAINING_DIR` directory as the directory argument, set the `batch_size` to 32, specify class_mode as 'binary' since it's a binary classification problem, and set the` target_size` to (64, 64) to resize the images.\n",
        "\n",
        "Similarly, for the validation generator, we pass the `VALIDATION_DIR` directory as the directory argument and set the same parameters as the training generator.\n",
        "\n",
        "Finally, we return the train_generator and `validation_generator` objects.\n",
        "\n",
        "By using these generator objects, we can efficiently load and preprocess the training and validation data for model training and evaluation."
      ],
      "metadata": {
        "id": "UlnHEALhgW5K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGE--c_9jT5c"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "  # Pass in the appropiate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(64, 64))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "  # Pass in the appropiate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=32,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(64, 64))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtQueA_RjWU0",
        "outputId": "8cb4cb68-233c-43e5-d24b-15517bc85d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22568 images belonging to 2 classes.\n",
            "Found 2509 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, TESTING_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model\n",
        "\n",
        "This introduction discusses the implementation of a model using transfer learning with the MobileNetV1 architecture. Transfer learning allows us to utilize the pre-trained MobileNetV1 model from TensorFlow Hub for our specific task. We create a model by incorporating the MobileNetV1 architecture as a feature extractor, adding additional layers on top for classification. The model is compiled with the Adam optimizer, binary cross-entropy loss, and accuracy as the evaluation metric. By leveraging transfer learning and MobileNetV1, we aim to develop an efficient and accurate model. Let's explore the implementation and evaluate its performance."
      ],
      "metadata": {
        "id": "FkIPFOuGLDxf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRrN5WgDjYr9"
      },
      "outputs": [],
      "source": [
        "mobilenetv1 = \"https://tfhub.dev/google/imagenet/mobilenet_v1_025_224/classification/5\"\n",
        "def create_model():\n",
        "  tl_layer = hub.KerasLayer(mobilenetv1, input_shape=(64, 64, 3), trainable=False)\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tl_layer,\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model\n",
        "\n",
        "In this introduction, we will discuss the training process of our model. We start by obtaining the untrained model using the `create_model()` function. The model consists of a MobileNetV1 feature extractor and additional classification layers.\n",
        "\n",
        "Next, we train the model using the `train_generator` for training data and `validation_generator` for validation data. The training process involves running 20 epochs, with 705 steps per epoch for training and 78 steps for validation.\n",
        "\n",
        "Please note that the training process may take some time, and it is essential to monitor the training progress and evaluate the model's performance.\n",
        "\n",
        "Let's explore the training process and analyze the history to gain insights into the model's learning and performance."
      ],
      "metadata": {
        "id": "QiR_hH88LV9W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8qD_HIijc_v",
        "outputId": "f5e185a2-cdb6-40b2-fc77-c25bed78bd85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "705/705 [==============================] - 154s 215ms/step - loss: 0.5116 - accuracy: 0.8471 - val_loss: 0.3054 - val_accuracy: 0.8786\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 31s 44ms/step - loss: 0.3010 - accuracy: 0.8810 - val_loss: 0.2930 - val_accuracy: 0.8838\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 29s 41ms/step - loss: 0.2766 - accuracy: 0.8879 - val_loss: 0.2777 - val_accuracy: 0.8862\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.2632 - accuracy: 0.8944 - val_loss: 0.2928 - val_accuracy: 0.8866\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.2541 - accuracy: 0.8976 - val_loss: 0.2875 - val_accuracy: 0.8926\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.2424 - accuracy: 0.9027 - val_loss: 0.2921 - val_accuracy: 0.8846\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.2313 - accuracy: 0.9074 - val_loss: 0.3042 - val_accuracy: 0.8894\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.2220 - accuracy: 0.9113 - val_loss: 0.3099 - val_accuracy: 0.8866\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.2182 - accuracy: 0.9124 - val_loss: 0.2998 - val_accuracy: 0.8914\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.2011 - accuracy: 0.9191 - val_loss: 0.3083 - val_accuracy: 0.8854\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.1952 - accuracy: 0.9223 - val_loss: 0.2988 - val_accuracy: 0.8926\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.1813 - accuracy: 0.9278 - val_loss: 0.3190 - val_accuracy: 0.8918\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.1773 - accuracy: 0.9322 - val_loss: 0.3475 - val_accuracy: 0.8874\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 27s 38ms/step - loss: 0.1754 - accuracy: 0.9325 - val_loss: 0.3489 - val_accuracy: 0.8826\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 29s 42ms/step - loss: 0.1627 - accuracy: 0.9378 - val_loss: 0.3442 - val_accuracy: 0.8806\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 28s 40ms/step - loss: 0.1515 - accuracy: 0.9410 - val_loss: 0.3815 - val_accuracy: 0.8826\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 28s 40ms/step - loss: 0.1403 - accuracy: 0.9437 - val_loss: 0.3943 - val_accuracy: 0.8870\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 28s 39ms/step - loss: 0.1389 - accuracy: 0.9468 - val_loss: 0.4171 - val_accuracy: 0.8782\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 29s 40ms/step - loss: 0.1278 - accuracy: 0.9509 - val_loss: 0.4378 - val_accuracy: 0.8866\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 28s 40ms/step - loss: 0.1296 - accuracy: 0.9515 - val_loss: 0.4321 - val_accuracy: 0.8726\n"
          ]
        }
      ],
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=20,\n",
        "                    steps_per_epoch = 705,\n",
        "                    validation_steps = 78,\n",
        "                    validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will discuss adding a summary of our model. After training the model, it is beneficial to examine its architecture and parameters. By calling the model.summary() function, we can obtain a summary that provides an overview of the model's layers, output shapes, and the total number of parameters.\n",
        "\n",
        "Analyzing the model summary allows us to gain insights into the model's structure and complexity. It helps in understanding the flow of information and the number of trainable parameters. This information is crucial for assessing the model's capacity and identifying potential areas for optimization.\n",
        "\n",
        "Let's add the model summary to our implementation and explore its details."
      ],
      "metadata": {
        "id": "JB3eceHFO5u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Menambahkan summary model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "v7Ftf7zrDu4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We retrieve the accuracy and loss values from the history object and plot them to observe the model's performance over the epochs.\n",
        "\n",
        "The accuracy plot illustrates the training and validation accuracy, indicating how well the model performs on both datasets. The loss plot represents the training and validation loss, indicating the amount of error during the training process.\n",
        "\n",
        "By analyzing these plots, we can evaluate the model's learning progress, identify potential overfitting or underfitting issues, and make informed decisions for further optimization.\n",
        "\n",
        "Let's visualize the training and validation results to gain insights into the model's performance.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iWQTTuklPIsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc      = history.history[     'accuracy' ]\n",
        "val_acc  = history.history[ 'val_accuracy' ]\n",
        "loss     = history.history[    'loss' ]\n",
        "val_loss = history.history['val_loss' ]\n",
        "\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  ( epochs,     acc, label='Training')\n",
        "plt.plot  ( epochs, val_acc, label='Validation')\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  ( epochs,     loss, label='Training')\n",
        "plt.plot  ( epochs, val_loss, label='Validation')\n",
        "plt.legend()\n",
        "plt.title ('Training and validation loss')"
      ],
      "metadata": {
        "id": "1mvcoFQMK_8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Model\n",
        "\n",
        "We load the test image using the image.load_img() function and specify the target size as (64, 64). This resizing ensures that the image is compatible with the input size expected by our model.\n",
        "\n",
        "By using a specific test image, we can evaluate how well our model performs on organic waste classification. This allows us to assess the model's ability to correctly classify the given image and make predictions based on its features.\n",
        "\n",
        "Let's proceed with loading the test image and examining its suitability for our model."
      ],
      "metadata": {
        "id": "OlhklPuQLKCj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bXZJ5dZvxRC"
      },
      "outputs": [],
      "source": [
        "# organic image\n",
        "test_image = image.load_img('./waste-dataset/data/testing/O/O_19.jpg',target_size = (64, 64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-3S9792w4Xb",
        "outputId": "f7959190-bdfa-4dc6-bafa-326c87fe09ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 396ms/step\n"
          ]
        }
      ],
      "source": [
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTW-oBE6xCIM",
        "outputId": "980a899f-caf4-4ecf-ea82-94fe16080cdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'O': 0, 'R': 1}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yY5SQPQWxOTN",
        "outputId": "2971ede1-e488-42b2-f885-fd07553fbfef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Organic'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if result[0][0] > 0.5:\n",
        "    prediction = 'Recyclable'\n",
        "else:\n",
        "    prediction = 'Organic'\n",
        "\n",
        "prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save & Export Model with TfLite"
      ],
      "metadata": {
        "id": "nDv2g_6cLlBb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5_2qdY5QTGh",
        "outputId": "439c115b-96c3-45fb-9000-b727353304dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./tf2-save\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./tf2-save\\assets\n"
          ]
        }
      ],
      "source": [
        "# run_model = tf.function(lambda x: model(x))\n",
        "\n",
        "# concrete_funct = run_model.get_concrete_function(tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
        "# tf.saved_model.save(\n",
        "#     model, 'tf2-save', signatures={\n",
        "#         tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: concrete_funct})\n",
        "!mkdir -p saved_model\n",
        "model.save('./tf2-save')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gtIKevGQTGh"
      },
      "outputs": [],
      "source": [
        "saved_model_dir = './tf2-save'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgSpFORDQTGh"
      },
      "outputs": [],
      "source": [
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}